"Casa Grande Solar", "Wilcox Solar", "St Johns Solar",
"Deming Solar")]
# ============================================
# Markowitz solver
# max  μᵀw - γ wᵀΣw  s.t. w >= 0, Σw = 1
# ============================================
solve_markowitz <- function(mu, Sigma, gamma = gamma0, lb = NULL, ub = NULL, solver = "OSQP") {
n <- length(mu)
w <- CVXR::Variable(n)
obj <- t(mu) %*% w - gamma * CVXR::quad_form(w, Sigma)
cons <- list(w >= 0, sum(w) == 1)
prob <- CVXR::Problem(CVXR::Maximize(obj), cons)
res  <- CVXR::solve(prob, solver = solver)
#im telling CVXR To maximize my objective function (obj)
#subject to consraints (cons)
#res = solver executes optimization
wv <- as.numeric(res$getValue(w))
list(
status   = res$status,
w        = wv,
exp_CF   = sum(mu * wv),
variance = as.numeric(t(wv) %*% Sigma %*% wv),
gamma    = gamma
)
}
# ============================================
# Single-γ solution
# ============================================
sol0 <- solve_markowitz(mu, Sigma, gamma = gamma0)
# ============================================
# Markowitz solver
# max  μᵀw - γ wᵀΣw  s.t. w >= 0, Σw = 1
# ============================================
solve_markowitz <- function(mu, Sigma, gamma = gamma0, lb = NULL, ub = NULL, solver = "OSQP") {
n <- length(mu)
w <- CVXR::Variable(n)
obj <- t(mu) %*% w - gamma * CVXR::quad_form(w, Sigma)
cons <- list(w >= 0, sum(w) == 1)
prob <- CVXR::Problem(CVXR::Maximize(obj), cons)
res  <- CVXR::solve(prob, solver = solver)
#im telling CVXR To maximize my objective function (obj)
#subject to consraints (cons)
#res = solver executes optimization
wv <- as.numeric(res$getValue(w))
list(
status   = res$status,
w        = wv,
exp_CF   = sum(mu * wv),
variance = as.numeric(t(wv) %*% Sigma %*% wv),
gamma    = gamma
)
}
# ============================================
# Single-γ solution
# ============================================
sol0 <- solve_markowitz(mu, Sigma, gamma = gamma0)
# ============================================
# Single-γ solution
# ============================================
sol0 <- solve_markowitz(mu, Sigma, gamma = gamma0)
# ============================================
#Site Summary Table
# ============================================
summary <- tibble(
Site     = sites,
Mean_CF  = mu,
Variance = apply(X, 2, var)
) |>
dplyr::arrange(dplyr::desc(Mean_CF))
con <- pipe("pbcopy", "w")
write.table(summary, con, sep = "\t", col.names = NA)
View(summary)
site_files <- c(
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/GC Junction Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Encino Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Medicine Bow Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Silver City Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Casa Grande Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Deming Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/GC Junction Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Kingman Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/St Johns Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Wilcox Solar.csv'
)
site_meta <- tibble(
file     = site_files,
sitename = site_names
) %>%
mutate(
tech = case_when(
str_detect(sitename, regex("wind",  ignore_case = TRUE)) ~ "Wind",
str_detect(sitename, regex("solar", ignore_case = TRUE)) ~ "Solar",
TRUE ~ "Unknown"
),
nameplate_kW = case_when(
tech == "Solar" ~ nameplate_solar_kW,
tech == "Wind"  ~ nameplate_wind_kW,
TRUE ~ NA_real_
)
)
nameplate_vec <- setNames(site_meta$nameplate_kW, site_meta$sitename)
df <- readr::read_csv(path, show_col_types = FALSE)
# ============================================
# CF Panel
# ============================================
read_site_long_cf <- function(path, sitename, nameplate_vec) {
np <- nameplate_vec[[sitename]]
if (is.null(np) || is.na(np)) {
stop(sprintf("No nameplate_kW found for site '%s'", sitename))
}
df <- readr::read_csv(path, show_col_types = FALSE)
stopifnot("Hour" %in% names(df))
df$Hour <- as.integer(df$Hour)
df_long <- df |>
tidyr::pivot_longer(
-Hour,
names_to  = "Year",
values_to = "Output_kW"
) |>
dplyr::mutate(
Year      = as.integer(Year),
Site      = sitename,
Output_kW = Output_kW,
CF        = Output_kW / np
) |>
dplyr::select(Year, Hour, Site, CF)
df_long
}
View(panel_cf)
# ============================================
# Build panel of CFs for all sites
# ============================================
panel_cf <- purrr::map2_dfr(
site_files, site_names,
~ read_site_long_cf(.x, .y, nameplate_vec = nameplate_vec)
)
# ============================================
# Build X matrix (hours x sites) amd the time data
# ============================================
build_X <- function(panel_cf) {
W <- panel_cf |>
dplyr::arrange(Year, Hour, Site) |>
tidyr::pivot_wider(names_from = Site, values_from = CF) |>
dplyr::arrange(Year, Hour)
site_cols <- setdiff(names(W), c("Year", "Hour"))
list(
X     = as.matrix(W[ , site_cols]),
sites = site_cols,
meta  = W[, c("Year", "Hour")]
)
}
bx    <- build_X(panel_cf)
View(bx)
#Hour x Site Matrix
X     <- bx$X
View(X)
View(X)
#A list of my sites (for labeling and joining metadata)
sites <- bx$sites
#time metadata
meta  <- bx$meta
View(meta)
#------------------------------------------------------------
# 1) Set folders
#------------------------------------------------------------
infolder  <- '/Users/nicktennes/Documents/SAM ERA5 Output 8760 CURRENT/Solar'   # dirty files
outfolder <- '/Users/nicktennes/Documents/SAM ERA5 Outpu 8760 CURRENT CLEAN'   # cleaned files
outfolder <- '/Users/nicktennes/Documents/SAM ERA5 Output 8760'   # cleaned files
dir.create(outfolder, showWarnings = FALSE)
#------------------------------------------------------------
# 2) List all CSVs (e.g., Deming.csv, StJohns.csv, etc.)
#------------------------------------------------------------
files <- list.files(infolder, pattern = "\\.csv$", full.names = TRUE)
#------------------------------------------------------------
# 3) Process each file
#------------------------------------------------------------
walk(files, function(f) {
message("Cleaning: ", basename(f))
# ---- Read dirty file WITH header row (run,1,2,3,...) ----
raw <- read_csv(f, show_col_types = FALSE)
# First column name (usually "run")
first_col <- names(raw)[1]
# ---- Row 1 (after header) has the long filenames & metadata ----
header_row <- raw[1, ]
# Build cleaned header:
# - first column becomes "Hour"
# - other columns: extract 4-digit year from filenames
header_clean <- header_row %>%
mutate(
!!first_col := "Hour",
across(-all_of(first_col), ~ {
x_chr <- as.character(.x)
yr <- str_extract(x_chr, "(19|20)\\d{2}")
ifelse(is.na(yr), x_chr, yr)
})
)
new_names <- as.character(header_clean[1, ])
# ---- Drop the metadata row we just used as header source ----
data <- raw[-1, ]
names(data) <- new_names
# ---- Identify year columns (everything except "Hour") ----
other_cols <- setdiff(names(data), "Hour")
year_nums <- suppressWarnings(as.integer(other_cols))
valid     <- !is.na(year_nums)
if (!any(valid)) {
warning("No valid year columns found in file: ", basename(f),
" — leaving as Hour + all other columns.")
data_clean <- data %>%
mutate(Hour = row_number())
} else {
year_cols <- other_cols[valid][order(year_nums[valid])]
# Keep Hour + year columns; drop rows that are all NA in year cols
data_clean <- data %>%
select(Hour, all_of(year_cols)) %>%
filter(!if_all(all_of(year_cols), ~ is.na(.))) %>%
mutate(Hour = row_number())   # reindex 1..n (ideally 1..8760)
}
# ---- Write cleaned file to output folder ----
outfile <- file.path(outfolder, basename(f))
write_csv(data_clean, outfile)
})
#------------------------------------------------------------
# 1) Set folders
#------------------------------------------------------------
infolder  <- '/Users/nicktennes/Documents/SAM ERA5 Output 8760 dirty/Solar'   # dirty files
outfolder <- '/Users/nicktennes/Documents/SAM ERA5 Output 8760'   # cleaned files
dir.create(outfolder, showWarnings = FALSE)
#------------------------------------------------------------
# 2) List all CSVs (e.g., Deming.csv, StJohns.csv, etc.)
#------------------------------------------------------------
files <- list.files(infolder, pattern = "\\.csv$", full.names = TRUE)
#------------------------------------------------------------
# 3) Process each file
#------------------------------------------------------------
walk(files, function(f) {
message("Cleaning: ", basename(f))
# ---- Read dirty file WITH header row (run,1,2,3,...) ----
raw <- read_csv(f, show_col_types = FALSE)
# First column name (usually "run")
first_col <- names(raw)[1]
# ---- Row 1 (after header) has the long filenames & metadata ----
header_row <- raw[1, ]
# Build cleaned header:
# - first column becomes "Hour"
# - other columns: extract 4-digit year from filenames
header_clean <- header_row %>%
mutate(
!!first_col := "Hour",
across(-all_of(first_col), ~ {
x_chr <- as.character(.x)
yr <- str_extract(x_chr, "(19|20)\\d{2}")
ifelse(is.na(yr), x_chr, yr)
})
)
new_names <- as.character(header_clean[1, ])
# ---- Drop the metadata row we just used as header source ----
data <- raw[-1, ]
names(data) <- new_names
# ---- Identify year columns (everything except "Hour") ----
other_cols <- setdiff(names(data), "Hour")
year_nums <- suppressWarnings(as.integer(other_cols))
valid     <- !is.na(year_nums)
if (!any(valid)) {
warning("No valid year columns found in file: ", basename(f),
" — leaving as Hour + all other columns.")
data_clean <- data %>%
mutate(Hour = row_number())
} else {
year_cols <- other_cols[valid][order(year_nums[valid])]
# Keep Hour + year columns; drop rows that are all NA in year cols
data_clean <- data %>%
select(Hour, all_of(year_cols)) %>%
filter(!if_all(all_of(year_cols), ~ is.na(.))) %>%
mutate(Hour = row_number())   # reindex 1..n (ideally 1..8760)
}
# ---- Write cleaned file to output folder ----
outfile <- file.path(outfolder, basename(f))
write_csv(data_clean, outfile)
})
# ============================================
# Libraries
# ============================================
library(dplyr)
library(tidyr)
library(purrr)
library(readr)
library(stringr)
library(ggplot2)
library(ggrepel)
library(CVXR)
site_files <- c(
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/GC Junction Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Encino Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Medicine Bow Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Silver City Wind.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Casa Grande Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Deming Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/GC Junction Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Kingman Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/St Johns Solar.csv',
'/Users/nicktennes/Documents/SAM ERA5 Output 8760/Wilcox Solar.csv'
)
# ============================================
# gamma (1st one for single optimization)
# ============================================
gamma0     <- 2
gamma_grid <- 10^seq(-10, 3, length.out = 50)
# ============================================
# Nameplate capacities
# ============================================
nameplate_solar_kW <- 100000
nameplate_wind_kW  <- 100000
# ============================================
# Site metadata: name, solar or wind, nameplate capacity
# ============================================
site_names <- basename(site_files) |> tools::file_path_sans_ext()
site_meta <- tibble(
file     = site_files,
sitename = site_names
) %>%
mutate(
tech = case_when(
str_detect(sitename, regex("wind",  ignore_case = TRUE)) ~ "Wind",
str_detect(sitename, regex("solar", ignore_case = TRUE)) ~ "Solar",
TRUE ~ "Unknown"
),
nameplate_kW = case_when(
tech == "Solar" ~ nameplate_solar_kW,
tech == "Wind"  ~ nameplate_wind_kW,
TRUE ~ NA_real_
)
)
nameplate_vec <- setNames(site_meta$nameplate_kW, site_meta$sitename)
# ============================================
# CF Panel
# ============================================
read_site_long_cf <- function(path, sitename, nameplate_vec) {
np <- nameplate_vec[[sitename]]
if (is.null(np) || is.na(np)) {
stop(sprintf("No nameplate_kW found for site '%s'", sitename))
}
df <- readr::read_csv(path, show_col_types = FALSE)
stopifnot("Hour" %in% names(df))
df$Hour <- as.integer(df$Hour)
df_long <- df |>
tidyr::pivot_longer(
-Hour,
names_to  = "Year",
values_to = "Output_kW"
) |>
dplyr::mutate(
Year      = as.integer(Year),
Site      = sitename,
Output_kW = Output_kW,
CF        = Output_kW / np
) |>
dplyr::select(Year, Hour, Site, CF)
df_long
}
# ============================================
# Build panel of CFs for all sites
# ============================================
panel_cf <- purrr::map2_dfr(
site_files, site_names,
~ read_site_long_cf(.x, .y, nameplate_vec = nameplate_vec)
)
View(panel_cf)
# ============================================
# Build X matrix (hours x sites) amd the time data
# ============================================
build_X <- function(panel_cf) {
W <- panel_cf |>
dplyr::arrange(Year, Hour, Site) |>
tidyr::pivot_wider(names_from = Site, values_from = CF) |>
dplyr::arrange(Year, Hour)
site_cols <- setdiff(names(W), c("Year", "Hour"))
list(
X     = as.matrix(W[ , site_cols]),
sites = site_cols,
meta  = W[, c("Year", "Hour")]
)
}
bx    <- build_X(panel_cf)
View(bx)
#Hour x Site Matrix
X     <- bx$X
View(X)
#A list of my sites (for labeling and joining metadata)
sites <- bx$sites
#time metadata
meta  <- bx$meta
View(meta)
# ============================================
# Derive HourOfDay, DayOfYear, Month
# ============================================
meta <- meta %>%
mutate(
HourOfDay = ((Hour - 1) %% 24),        # 0–23
DayOfYear = ((Hour - 1) %/% 24) + 1    # 1–365
) %>%
mutate(
Month = case_when(
DayOfYear <= 31                                      ~ 1,
DayOfYear <= 31 + 28                                 ~ 2,
DayOfYear <= 31 + 28 + 31                            ~ 3,
DayOfYear <= 31 + 28 + 31 + 30                       ~ 4,
DayOfYear <= 31 + 28 + 31 + 30 + 31                  ~ 5,
DayOfYear <= 31 + 28 + 31 + 30 + 31 + 30             ~ 6,
DayOfYear <= 31 + 28 + 31 + 30 + 31 + 30 + 31        ~ 7,
DayOfYear <= 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31   ~ 8,
DayOfYear <= 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31 + 30 ~ 9,
DayOfYear <= 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31 + 30 + 31 ~ 10,
DayOfYear <= 31 + 28 + 31 + 30 + 31 + 30 + 31 + 31 + 30 + 31 + 30 ~ 11,
TRUE ~ 12
)
)
# ============================================
# Mean & covariance of CF
# ============================================
mu    <- colMeans(X)
Sigma <- stats::cov(X)
# ============================================
#Site Summary Table
# ============================================
summary <- tibble(
Site     = sites,
Mean_CF  = mu,
Variance = apply(X, 2, var)
) |>
dplyr::arrange(dplyr::desc(Mean_CF))
View(summary)
# ============================================
# Markowitz solver
# max  μᵀw - γ wᵀΣw  s.t. w >= 0, Σw = 1
# ============================================
solve_markowitz <- function(mu, Sigma, gamma = gamma0, lb = NULL, ub = NULL, solver = "OSQP") {
n <- length(mu)
w <- CVXR::Variable(n)
obj <- t(mu) %*% w - gamma * CVXR::quad_form(w, Sigma)
cons <- list(w >= 0, sum(w) == 1)
prob <- CVXR::Problem(CVXR::Maximize(obj), cons)
res  <- CVXR::solve(prob, solver = solver)
#im telling CVXR To maximize my objective function (obj)
#subject to consraints (cons)
#res = solver executes optimization
wv <- as.numeric(res$getValue(w))
list(
status   = res$status,
w        = wv,
exp_CF   = sum(mu * wv),
variance = as.numeric(t(wv) %*% Sigma %*% wv),
gamma    = gamma
)
}
# ============================================
# Single-γ solution
# ============================================
sol0 <- solve_markowitz(mu, Sigma, gamma = gamma0)
cat("\n--- Single-γ solution ---\n")
print(
tibble(Site = sites, Weight = round(sol0$w, 4)) |>
dplyr::arrange(dplyr::desc(Weight))
)
cat(sprintf("γ=%g | E[CF]=%.4f | Var=%.4f\n", sol0$gamma, sol0$exp_CF, sol0$variance))
fronttable <- tibble(Site = sites, Weight = round(sol0$w, 4))
con <- pipe("pbcopy", "w")
# ============================================
# Efficient frontier along gamma grid
# ============================================
front <- lapply(gamma_grid, function(g) solve_markowitz(mu, Sigma, gamma = g))
frontier <- tibble(
gamma    = sapply(front, `[[`, "gamma"),
exp_CF   = sapply(front, `[[`, "exp_CF"),
variance = sapply(front, `[[`, "variance")
) |>
dplyr::arrange(variance)
cat("\n--- Efficient frontier (full year, head) ---\n")
print(head(frontier, 20))
# ggplot frontier + single-site points
ggplot() +
geom_line(data = frontier, aes(x = variance, y = exp_CF),
linewidth = 0.7, color = "darkblue") +
geom_point(data = frontier, aes(x = variance, y = exp_CF),
size = 1.5, color = "darkblue", alpha = 0.7) +
geom_point(data = summary, aes(x = Variance, y = Mean_CF),
color = "red", size = 2) +
geom_text_repel(
data = summary,
aes(x = Variance, y = Mean_CF, label = Site),
size = 3,
color = "red"
) +
labs(
x = "Variance of Capacity Factor",
y = "Expected Capacity Factor",  # change to (%) if you multiply Mean_CF by 100
title = "Efficient Frontier with Single-Site Portfolios"
) +
theme_minimal(base_size = 12)
# ============================================
# July–August subset
# ============================================
idx_JA <- which(meta$Month %in% c(7, 8))
View(fronttable)
View(fronttable)
View(frontier)
View(summary)
WindSolar <- X[, c("Medicine Bow Wind", "Encino Wind", "Silver City Wind",
"GC Junction Wind", "Kingman Solar","GC Junction Solar",
"Casa Grande Solar", "Wilcox Solar", "St Johns Solar",
"Deming Solar")]
cor_WindSolar <- cor(WindSolar, use = "pairwise.complete.obs")
View(cor_WindSolar)
